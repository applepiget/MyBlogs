---
title: MYDB项目总结
date: 2025-04-14 14:16:48
tags: MySQL
---

# MYDB

1.为什么使用NIO，有哪些好处



2.日志是怎么做的



3.如何处理可见性

​	1）根据数据库不同的隔离级别来保证不同的可见性

​	2）**读未提交**：这时不对事务的可见性做任何处理，可能会导致脏读、不可重复读、幻读；

​	3）**读提交**：引入MVCC

​		**在读提交隔离级别下如何判断一条记录是否对当前事务可见**：
​		1）获取当前数据记录的xmin和xmax；

​		2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；

​		3）判断创建该数据记录的事务是否提交，如果已经提交，进一步进行判断，否则说明当前事务为完成，该数据记录对当前事务不可见；

​		4）如果创建该数据记录的事务已经提交，并且xmax不存在，说明该记录违背删除或者修改，该记录对当前事务可见；

​		5）如果xmax存在，并且不等于当前事务id，判断xmax事务是否已经提交，若xmax事务还未提交，说明该数据记录对当前版本仍然可见。

​	4）**读未提交**：同样引入MVCC

​		**在可重复读隔离级别下如何判断一条记录是否对当前事务可见**：

​		1）获取当前数据记录的xmin和xmax；

​		2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；

​		3）如果xmin事务已经提交，并且xmin < xid，同时xmin事务已经提交，xmax不存在，说明该数据记录对当前事务可见；

​		4）如果事务xmax存在，并且xmax不等于xid，如果事务xmax还未提交，或这事务xmax是再当前事务开始后才开始的，又或是事务xmax还处在获活跃状态，说明该数据记录对当前事务是可见的。

​	5）**串行化**：使用两阶段锁，如果某个事务 i 已经对 x 加锁，且另一个事务 j 也想操作 x，但是这个操作与事务 i 之前的操作相互冲突的话，事务 j 就会被阻塞。譬如，T1 已经因为 U1(x) 锁定了 x，那么 T2 对 x 的读或者写操作都会被阻塞，T2 必须等待 T1 释放掉对 x 的锁。



4.ACID如何实现

​	1）原子性：项目中的事务分为活跃、提交和回滚三个状态，主要是通过对事务状态的保存来确保事务的原子性；

​	2）持久性：通过记录日志来保证数据库的持久性，以及事务提交时强制刷盘，保证数据已经写入磁盘中，一次来保证数据库的持久性；

​	3）一致性：通过实现其他三种性质来保证一致性；

​	4）隔离性：通过数据库中实现的MVCC来保证数据之间的隔离性。



5.死锁如何处理

​	1）当一个事务请求获取某个资源时，首先会检查该资源是否已被其他事务持有。如果没有被持有，资源将直接分配给请求的事务。如果资源已被占用，事务将进入等待状态，并存储在相应的等待队列中。

​	2）在某些情况下，事务可能会由于等待时间过长而被回滚。通过后台线程定期检查每个事务的等待时间，并在超时时执行回滚操作。 超时检测与回滚机制的基本思想是：

- 每个事务在获取资源时，如果资源被其他事务占用，则需要等待。
- 为了避免长时间等待导致系统资源被锁住，我们为每个等待的事务设置一个超时时间（30S）。
- 当检测到事务等待超时后，系统将回滚这个事务，并释放它占用的所有资源，从而避免死锁或资源饥饿。

启动一个后台线程，定期检查每个事务的等待时间。如果超时，则执行回滚操作。



6.存储和空间回收如何处理

​	MVCC的版本清理：若当前版本的事务ID已提交且无活跃事务引用，则可以清除该版本



7.介绍下项目中的B+树



8.SQL语句解析

​	1）将SQL语句解析为多个token，其中引号中的内容被当作一个token

​	2）根据SQL语句的第一个字段来执行不同的操作



9.MYDB中锁是如何实现的

​	MYDB中的锁是**两阶段锁**，引入两阶段锁的主要目的是为了让数据库实现**可串行化**级别的事务隔离。

​	**串行化（Serializable）**：是最高级别的事务隔离，确保事务像是按顺序一个接一个执行的，从而避免了所有的并发问题。在这个级别下，事务之间不会相互影响，彻底解决了脏读、不可重复读和幻读问题。 在 EasyDB 中，串行化通过强制事务之间的完全隔离来实现。在串行化隔离级别下，每个事务只能看到它开始之前已经提交的版本，以及它自己创建或修改的版本。此逻辑与可重复读的一致性逻辑相似。

​	**两阶段锁**：如果某个事务 i 已经对 x 加锁，且另一个事务 j 也想操作 x，但是这个操作与事务 i 之前的操作相互冲突的话，事务 j 就会被阻塞。譬如，T1 已经因为 U1(x) 锁定了 x，那么 T2 对 x 的读或者写操作都会被阻塞，T2 必须等待 T1 释放掉对 x 的锁。

***



### 1.TM (Transaction Manager) 事务管理

（1）XID 事务ID，每个事务对应一个ID

（2）事务状态，**active/活跃，commited/提交，aborted/回滚**

（3）文件读写采用NIO，NIO与BIO的对比如下

​		阻塞与非阻塞

- **BIO**：在进行 I/O 操作时，线程会被阻塞。比如在读取数据时，线程会一直等待直到数据完全读取完毕；在写入数据时，会一直等待直到数据全部写入。这种阻塞特性会导致线程在等待过程中无法进行其他工作，造成资源浪费。举例来说，一个服务器使用 BIO 处理多个客户端连接时，每个连接都需要一个独立的线程来处理，若某个客户端连接数据传输缓慢，会使对应线程长时间阻塞，影响系统整体性能。
- **NIO**：采用非阻塞模式，线程在进行 I/O 操作时不会被阻塞，可以去执行其他任务。线程可以询问是否有数据准备好，若没有则可以继续执行其他代码，之后再回来检查。例如，服务器使用 NIO 时，一个线程可以处理多个客户端连接，当某个连接没有数据可读时，线程不会等待，而是去处理其他连接，提高了线程的利用率。

​		**多路复用机制**

- **BIO**：缺乏有效的多路复用机制，若要处理多个客户端连接，通常需要为每个连接创建一个独立的线程。线程的创建和销毁会带来较大的开销，并且过多的线程会导致系统资源竞争激烈，增加上下文切换的开销，降低系统性能。
- **NIO**：引入了选择器（Selector），它是 NIO 实现多路复用的核心。一个选择器可以同时监听多个通道（Channel）的事件，如读、写、连接等。线程可以通过选择器来轮询哪些通道有事件发生，然后对这些通道进行相应的处理。这样，一个线程就可以处理多个客户端连接，减少了线程的使用数量，降低了系统开销。

​		缓冲区与通道

- **BIO**：使用流（Stream）的方式进行数据传输，数据的读写是单向的，输入流只能读，输出流只能写。而且流的操作是基于字节或字符的，每次只能处理一个或多个字节 / 字符，效率较低。
- **NIO**：采用缓冲区（Buffer）和通道（Channel）的方式进行数据传输。通道是双向的，可以同时进行读写操作，提高了数据传输的灵活性。缓冲区是一个连续的内存块，数据可以批量地从通道读取到缓冲区，或者从缓冲区写入到通道，减少了数据的复制次数，提高了数据传输的效率。

（4）**begin()**方法，开启一个事务并将其设置为活跃状态，同时事务id计数器自增

（5）**updateXID()**方法，更新事务状态，后面的**commit()** ,**abort()**方法就可以直接借助 **updateXID()** 方法实现

（6）检查事务状态的三个方法 **isActive(), isCommited(), isAborted()**

（7）静态方法**create()**，创建一个XID文件

（8）静态方法**open()**，从一个已有的XID文件来创建TM



***



### 2.DM (Data Manager) 数据管理

（1）DM直接管理**数据库DB文件**和**日志文件**，具体职责如下：1）分页管理DB文件，并进行缓存；2）管理日志文件，保证数据库在发生错误时根据日志进行恢复；3）抽象DB文件为DataItem，提供给尚存使用，并提供缓存

（2）引用计数法设计缓存，当计数为0时，直接从缓存中删除这个资源；同时，缓存满了之后应该直接报错。定义了一个抽象类：

```java
AbstractCache<T>
/**
 * 当资源不在缓存时的获取行为
 */
protected abstract T getForCache(long key) throws Exception;
/**
 * 当资源被驱逐时的写回行为
 */
protected abstract void releaseForCache(T obj);
```

同时，为应对多线程并发场景，额外记录了哪些资源正在被读取，构造了以下三个数据结构：

```java
private HashMap<Long, T> cache;                     // 实际缓存的数据
private HashMap<Long, Integer> references;          // 资源的引用个数
private HashMap<Long, Boolean> getting;             // 正在被获取的资源
```

因此在读取缓存时，首先进入死循环，一直尝试从缓存中获取数据，同时检查是否有其他线程正在使用这个数据；

如果数据在缓存中，直接返回，同时引用计数+1；

如果不在缓存中，首先在**getting**中对数据进行标记，表示其正在被使用，在用**getForCache(long key)**获取缓存。



***

### 3.数据页的缓存与管理

（1）DM向下将文件系统抽象成页面，每次对文件的读写都是以页面为单位的，同时缓存也是以页面为单位进行的，页面缓存存储在内存中。

（2）**数据页大小为8K**，借用上一节已经实现的引用计数缓存框架进行缓存，数据页的数据结构如下：

```java
public class PageImpl implements Page{
	private int pageNumber;	//页号
    private byte[] data;	//数据内容
    private boolean ditry; 	//是否为脏页
    private Lock lock;
    
    private PageCache pc;
}
```

（3）获取缓存**getForCache(long key)**，传入的参数为页号

````java
protected Page getForCache(long key) throws Exception {
    int pgno = (int)key;
    long offset = PageCacheImpl.pageOffset(pgno);

    ByteBuffer buf = ByteBuffer.allocate(PAGE_SIZE);
    fileLock.lock();
    try {
        //通过偏移量获取文件开始读写的位置
        fc.position(offset);
        fc.read(buf);
    } catch(IOException e) {
        Panic.panic(e);
    }
    fileLock.unlock();
    return new PageImpl(pgno, buf.array(), this);
}

private static long pageOffset(int pgno) {
    // 页号从 1 开始
    return (pgno-1) * PAGE_SIZE;
}
````

（4）驱逐页面**releaseForCache(Page pg)**，

```java
protected void releaseForCache(Page pg) {
    if(pg.isDirty()) {
        flush(pg);
        pg.setDirty(false);
    }
}

private void flush(Page pg) {
    int pgno = pg.getPageNumber();
    long offset = pageOffset(pgno);

    fileLock.lock();
    try {
        //将数据包装成页面
        ByteBuffer buf = ByteBuffer.wrap(pg.getData());
        //确定读写位置
        fc.position(offset);
        //写入缓存
        fc.write(buf);
        //刷回磁盘
        fc.force(false);
    } catch(IOException e) {
        Panic.panic(e);
    } finally {
        fileLock.unlock();
    }
}
```

（5）使用了一个AtomicInteger，记录当前打开的数据库文件有多少页。

（6）同一条数据不允许跨页存储。

（7）数据库的第一页用来做启动检查，具体原理是，每次启动数据库的时候，会生成一段随机字节，存储在 100 ~ 107 字节。在数据库正常关闭时，会将这串字节，拷贝到第一页的 108 ~ 115 字节。这样数据库在每次启动时，就会检查第一页两处的字节是否相同，以此来判断上一次是否正常关闭。如果是异常关闭，就需要执行数据的恢复流程。

（8）对于普通页的管理与第一页不同。普通页面以一个 2字节无符号数开始，表示这一页的空闲指针，在写前读取空闲指针，并在写后更新空闲指针

（9）**recoverInsert()**和**recoverUpdate()**用于在数据库崩溃后重新打开，在下一章中会用到



***

### 4.日志文件和恢复策略

（1）DM每次对数据文件进行操作时，都会记录一条日志到磁盘；数据库崩溃后，再次启动时可以根据日志内容恢复数据文件，保持其一致性。

日志的二进制文件，按照如下的格式进行排布：

```
[XChecksum][Log1][Log2][Log3]...[LogN][BadTail]
```

其中 XChecksum 是一个四字节的整数，是对后续所有日志计算的校验和。Log1 ~ LogN 是常规的日志数据，BadTail 是在数据库崩溃时，没有来得及写完的日志数据，这个 BadTail 不一定存在。



（2）每条日志的格式如下：

```java
[Size][Checksum][Data]
```

（3）在打开一个日志文件时，需要首先校验日志文件的 XChecksum，并移除文件尾部可能存在的 BadTail，由于 BadTail 该条日志尚未写入完成，文件的校验和也就不会包含该日志的校验和，去掉 BadTail 即可保证日志文件的一致性。

（4）向日志文件中写入文件时，先写入文件在更新文件的校验和，更新校验和时使用FileChannel的**force()**方法保证文件会被刷回磁盘

（5）DM向上提供了两种操作：插入和更新，在进行插入和更新前，必须保证日志写入后，才能够对数据进行操作。

对于两种数据操作，DM 记录的日志如下：

- (Ti, I, A, x)，表示事务 Ti 在 A 位置插入了一条数据 x
- (Ti, U, A, oldx, newx)，表示事务 Ti 将 A 位置的数据，从 oldx 更新成 newx



如果不考虑并发的情况，那么在某一时刻，只可能有一个事务在操作数据库。日志会看起来像下面那样：

```
(Ti, x, x), ..., (Ti, x, x), (Tj, x, x), ..., (Tj, x, x), (Tk, x, x), ..., (Tk, x, x)
```

**对于单线程**，Ti、Tj 和 Tk 的日志永远不会相交。这种情况下利用日志恢复很简单，假设日志中最后一个事务是 Ti：

1. 对 Ti 之前所有的事务的日志，进行重做（redo）
2. 接着检查 Ti 的状态（XID 文件），如果 Ti 的状态是已完成（包括 committed 和 aborted），就将 Ti 重做，否则进行撤销（undo）

接着，是如何对事务 T 进行 redo：

1. 正序扫描事务 T 的所有日志
2. 如果日志是插入操作 (Ti, I, A, x)，就将 x 重新插入 A 位置
3. 如果日志是更新操作 (Ti, U, A, oldx, newx)，就将 A 位置的值设置为 newx

undo 也很好理解：

1. 倒序扫描事务 T 的所有日志
2. 如果日志是插入操作 (Ti, I, A, x)，就将 A 位置的数据删除
3. 如果日志是更新操作 (Ti, U, A, oldx, newx)，就将 A 位置的值设置为 oldx



**对于多线程：**

规定1：正在进行的事务，不会读取其他任何未提交的事务产生的数据。

规定2：正在进行的事务，不会修改其他任何未提交的事务修改或产生的数据。



***

### 5.页面索引与DM实现

页面索引，缓存了每一页的空闲空间。用于在上层模块进行插入操作时，能够快速找到一个合适空间的页面，而无需从磁盘或者缓存中检查每一个页面的信息。



***

### 6.记录的版本&事务隔离

（1）**两阶段锁**：如果某个事务 i 已经对 x 加锁，且另一个事务 j 也想操作 x，但是这个操作与事务 i 之前的操作相互冲突的话，事务 j 就会被阻塞。譬如，T1 已经因为 U1(x) 锁定了 x，那么 T2 对 x 的读或者写操作都会被阻塞，T2 必须等待 T1 释放掉对 x 的锁。

​	2PL 确实保证了调度序列的可串行化，但是不可避免地导致了事务间的相互阻塞，甚至可能导致死锁。为了提高事务处理的效率，降低阻塞概率，实现了 MVCC。

（2）**MVCC**：VM(版本管理)管理所有的数据项，并向上层提供数据记录的概念，上层模块通过VM操作数据记录。VM内部为每个数据记录维护了多个版本，每当上层模块对某个数据记录进行修改时，VM就会为这个记录创建一个新的版本。

（3）一条数据记录中存储的数据格式如下：

```
[XMIN] [XMAX] [DATA]
```

（4）**事务的隔离级别**：

**读提交**：防止级联回滚；实现读提交，为每个版本维护了两个变量，就是上面提到的 XMIN 和 XMAX：

- XMIN：创建该版本的事务编号
- XMAX：删除该版本的事务编号

XMIN 应当在版本创建时填写，而 XMAX 则在版本被删除，或者有新版本出现时填写。XMAX 这个变量，也就解释了为什么 DM 层不提供删除操作，当想删除一个版本时，只需要设置其 XMAX，这样，这个版本对每一个 XMAX 之后的事务都是不可见的，也就等价于删除了。

**在读提交隔离级别下如何判断一条记录是否对当前事务可见**：
1）获取当前数据记录的xmin和xmax；

2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；

3）判断创建该数据记录的事务是否提交，如果已经提交，进一步进行判断，否则说明当前事务为完成，该数据记录对当前事务不可见；

4）如果创建该数据记录的事务已经提交，并且xmax不存在，说明该记录违背删除或者修改，该记录对当前事务可见；

5）如果xmax存在，并且不等于当前事务id，判断xmax事务是否已经提交，若xmax事务还未提交，说明该数据记录对当前版本仍然可见。



**可重复读**：解决不可重复读的问题，即一个事务执行期间对同一个数据向多次读取得到不同的结果；

为实现可重复读，规定当前事务运行时需要忽略：
1）再本事务后开始的事务所更新的数据，通过比较事务ID实现；

2）本事务开始时，还是活跃状态事务的数据，通过再当前事务开始时，记录下当前所有活跃的事务ID；**重要**：如果xmin也在这个活跃事务的集合中，这个数据也应当对当前事务不可见。

**在可重复读隔离级别下如何判断一条记录是否对当前事务可见**：

1）获取当前数据记录的xmin和xmax；

2）如果当前事务id等于xmin（即这条数据记录由当前事务创建）并且xmax等与null，说明该数据记录对当前事务可见；

3）如果xmin事务已经提交，并且xmin < xid，同时xmin事务已经提交，xmax不存在，说明该数据记录对当前事务可见；

4）如果事务xmax存在，并且xmax不等于xid，如果事务xmax还未提交，或这事务xmax是再当前事务开始后才开始的，又或是事务xmax还处在获活跃状态，说明该数据记录对当前事务是可见的。



***

### 7.死锁检测与VM实现

（1）MVCC 的实现，使得 MYDB 在撤销或是回滚事务很简单：只需要将这个事务标记为 aborted 即可。根据前一章提到的可见性，每个事务都只能看到其他 committed 的事务所产生的数据，一个 aborted 事务产生的数据，就不会对其他事务产生任何影响了，也就相当于，这个事务不曾存在过。

（2）**版本跳跃问题**：版本跳跃问题，考虑如下的情况，假设 X 最初只有 x0 版本，T1 和 T2 都是可重复读的隔离级别：

```
T1 begin
T2 begin
R1(X) // T1读取x0
R2(X) // T2读取x0
U1(X) // T1将X更新到x1
T1 commit
U2(X) // T2将X更新到x2
T2 commit
```

​	这种情况实际运行起来是没问题的，但是逻辑上不太正确。T1 将 X 从 x0 更新为了 x1，这是没错的。但是 T2 则是将 X 从 x0 更新成了 x2，跳过了 x1 版本。

​	读提交是允许版本跳跃的，而可重复读则是不允许版本跳跃的。解决版本跳跃的思路也很简单：如果 Ti 需要修改 X，而 X 已经被 Ti 不可见的事务 Tj 修改了，那么要求 Ti 回滚。

​	事务Ti不可见事务Tj有两种情况：

​	1）Ti的事务id小于Tj的事务id，即Tj是在Ti开始后才开始的

​	2）事务Ti开始时，Tj仍处于活跃状态

